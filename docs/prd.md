# PRD: Інтелектуальний маршрутизатор моделей BMAD (Версія 2.0)

## 1. Цілі та контекст

### Цілі (Розширені)

* **Для користувача:** Радикально знизити вартість використання **будь-яких LLM-моделей (Antropic, Gemini, OpenAI, а також локальних, що працюють через Ollama чи подібні)**, шляхом автоматичного вибору найбільш економічно доцільної та продуктивної моделі для кожного конкретного запиту, зберігаючи при цьому високу якість результатів.
* **Для продукту (BMAD-METHOD):** Створити універсальний, інтелектуальний LLM-шлюз, що стане центральним компонентом екосистеми BMAD. Це надасть користувачам унікальну гнучкість, контроль над витратами та можливість використовувати найкращі інструменти від різних провайдерів (включаючи локальні моделі для максимальної приватності та швидкості) для будь-якого завдання.

### Контекст

Початковий аналіз виявив неефективність використання однієї моделі для всіх завдань. Це розширення визнає, що проблема не обмежується одним провайдером. Сучасний ландшафт ШІ пропонує безліч моделей, кожна з яких має свої сильні сторони та вартість. Користувачі BMAD не повинні бути прив'язані до одного провайдера або вручну жонглювати різними інструментами. Цей PRD описує створення єдиної системи, яка абстрагує складність вибору та надає найкращий результат за найкращою ціною, незалежно від джерела моделі.

### Журнал змін

| Дата       | Версія | Опис                                                              | Автор |
| :--------- | :----- | :---------------------------------------------------------------- | :---- |
| 15.06.2025 | 1.0    | Початковий проєкт для бінарного роутера Claude                     | PM    |
| **15.06.2025** | **2.0** | **Розширення до мульти-провайдерного LLM-шлюзу (OpenAI, Gemini, Ollama)** | **PM** |

## 2. Вимоги

### Функціональні вимоги (FR)

* **FR1: Аналіз складності запиту:** Система повинна автоматично аналізувати кожен запит користувача перед його відправленням, щоб визначити його намір та складність.
* **FR2: Інтелектуальна маршрутизація (Мульти-модель):** На основі аналізу система повинна автоматично направляти запит до найкращої моделі з **усього пулу підключених провайдерів (Anthropic, OpenAI, Gemini, локальні)**, враховуючи їхні можливості, вартість та поточну завантаженість.
* **FR3: Ручне керування (Розширене):** Користувач повинен мати можливість легко обрати **провайдера та конкретну модель** (наприклад, `OpenAI: GPT-4o`, `Local: Llama3`) для свого запиту.
* **FR4: Прозорість і звітність:** Інтерфейс має чітко показувати, **який провайдер та яка модель** були використані.
* **FR5: Автоматизований гібридний режим (Мульти-модель):** Система повинна дозволяти використовувати **найкращу модель для планування** (наприклад, `Claude 3 Opus` або `GPT-4o`) та **найкращу модель для виконання** (наприклад, `Gemini 1.5 Flash` або локальну `Llama3`) в рамках одного завдання.
* **FR6: Налаштовувані стратегії:** Користувач може обрати одну з попередньо налаштованих стратегій.
* **FR7: Підключення до API-провайдерів:** Система повинна підтримувати автентифікацію та відправку запитів до API Anthropic, OpenAI та Google (Gemini).
* **FR8: Підключення до локальних моделей:** Система повинна підтримувати з'єднання з локальними серверами, що працюють за стандартом Ollama.
* **FR9: Керування ключами та ендпоінтами:** Користувач повинен мати безпечний інтерфейс для введення своїх API-ключів для хмарних провайдерів та адреси ендпоінта для локального сервера.
* **FR10: Конфігурована матриця моделей:** Система повинна використовувати конфігураційний файл, що описує можливості, відносну вартість та сильні сторони кожної моделі, щоб приймати рішення щодо маршрутизації.

### Нефункціональні вимоги (NFR)

* **NFR1: Продуктивність:** Затримка маршрутизації має бути мінімальною.
* **NFR2: Надійність вибору:** Система повинна обирати оптимальну модель з усього пулу з високою надійністю.
* **NFR3: Економія коштів:** Основна мета — значне зниження загальних витрат.
* **NFR4: Інтеграція:** Глибока інтеграція в ядро BMAD-METHOD.
* **NFR5: Розширюваність:** Архітектура повинна дозволяти легко додавати нових провайдерів або моделі в майбутньому, мінімально змінюючи код.

## 3. Епіки

### Епік 1: Ядро мульти-провайдерної інтеграції

**Мета:** Створити уніфікований шар для взаємодії з різними LLM-провайдерами та налаштування їх підключення.

* **Історія 1.1:** Створити UI для безпечного введення та зберігання API-ключів для OpenAI, Anthropic, Gemini та URL для Ollama.
* **Історія 1.2:** Реалізувати уніфікований адаптер, що може відправляти запити та отримувати відповіді від API OpenAI.
* **Історія 1.3:** Розширити адаптер для підтримки API Anthropic.
* **Історія 1.4:** Розширити адаптер для підтримки API Google Gemini.
* **Історія 1.5:** Розширити адаптер для підтримки локального сервера Ollama.
* **Історія 1.6:** Оновити UI для ручного вибору моделі, показуючи всі налаштовані моделі, згруповані за провайдерами.

### Епік 2: Інтелектуальний рушій маршрутизації v1

**Мета:** Реалізувати базову логіку автоматичного вибору найкращої моделі з усіх доступних.

* **Історія 2.1:** Створити конфігураційний файл (матрицю моделей), що описує характеристики кожної моделі (вартість, швидкість, сильні сторони: код, креативність, аналіз).
* **Історія 2.2:** Реалізувати аналізатор запитів, що визначає намір та складність.
* **Історія 2.3:** Створити ядро рушія маршрутизації, яке на основі аналізу запиту та матриці моделей обирає найкращий варіант.
* **Історія 2.4:** Інтегрувати рушій у BMAD, щоб автоматичний режим працював за замовчуванням.

### Епік 3: Розширені стратегії та гібридний режим

**Мета:** Надати користувачам потужні інструменти для складних завдань та гнучкого керування.

* **Історія 3.1:** Реалізувати підтримку налаштовуваних стратегій ("Економія", "Якість", "Баланс") у рушії маршрутизації.
* **Історія 3.2:** Реалізувати гібридний режим, що дозволяє обрати одну модель для "Планування" (наприклад, `GPT-4o`) та іншу для "Виконання" (наприклад, `Llama3`).
* **Історія 3.3:** Реалізувати візуалізацію економії, показуючи користувачу, скільки коштів було заощаджено завдяки інтелектуальній маршрутизації.
